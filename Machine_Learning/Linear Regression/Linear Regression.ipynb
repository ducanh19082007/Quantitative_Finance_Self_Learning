{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a040185",
   "metadata": {},
   "source": [
    "# 1. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea5a4ad",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    "w_1 \\\\\n",
    "w_2 \\\\\n",
    "\\vdots \\\\\n",
    "w_n\n",
    "\\end{bmatrix}\n",
    "\\times\n",
    "\\begin{bmatrix}\n",
    "x_1^{(1)} & x_2^{(1)} & \\cdots & x_n^{(1)} \\\\\n",
    "x_1^{(2)} & x_2^{(2)} & \\cdots & x_n^{(2)} \\\\\n",
    "x_1^{(3)} & x_2^{(3)} & \\cdots & x_n^{(3)} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_1^{(m)} & x_2^{(m)} & \\cdots & x_n^{(m)}\n",
    "\\end{bmatrix}\n",
    "+ b =\n",
    "\\begin{bmatrix}\n",
    "y^{(1)} & y^{(2)} & \\dots & y^{(m)}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "with (i) as the number of iteration, with i = 0 as the input \n",
    "\n",
    "or it can be interpreted as:\n",
    "$$\n",
    "W.X + b = Y\n",
    "$$\n",
    "to find W, we have:\n",
    "\n",
    "$$\n",
    "W= \\frac{\\text{Y  -  b}}{\\text{X}}\\huge\n",
    "$$\n",
    "given that Y-b as b has been accounted inside y\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "y^{(1)}-b & y^{(2)}-b & \\dots & y^{(m)}-b\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "with X^T (or in python we can make this as `X.T`), X^T is the transpose of X, with the column -> row and vice versa, meaning the X is in n x m size, the X^T is m x n\n",
    "\n",
    "$$\n",
    "X^T(X.W - Y) = 0\n",
    "$$\n",
    "$$\n",
    "X^T.X.W - X^T.Y = 0\n",
    "$$\n",
    "$$\n",
    "X^T.X.W = X^T.Y\n",
    "$$\n",
    "$$\n",
    "w=(X^T.X)^{âˆ’1}X^T.y\n",
    "$$\n",
    "\n",
    "Taking the gradient of the loss with respect to $\\boldsymbol{\\beta}$ yields (MSE)\n",
    "\n",
    "$$\n",
    "\\nabla_{\\boldsymbol{\\beta}} \\mathcal{L}\n",
    "= \\frac{1}{n} X^\\top (X\\boldsymbol{\\beta} - \\mathbf{y}).\n",
    "$$\n",
    "\n",
    "> ## Update Equation for Weight (and also for bias)\n",
    "> $$\n",
    "> \\boxed{\n",
    "> \\boldsymbol{\\beta}^{(t+1)}\n",
    "> =\n",
    "> \\boldsymbol{\\beta}^{(t)}\n",
    "> -\n",
    "> \\eta \\cdot \\frac{1}{n} X^\\top\n",
    "> \\left( X\\boldsymbol{\\beta}^{(t)} - \\mathbf{y} \\right)\n",
    "> }\n",
    "> $$\n",
    "\n",
    "\n",
    "### Coordinate-wise Update\n",
    "\n",
    "Equivalently, for each coefficient $\\beta_j$,\n",
    "\n",
    "$$\n",
    "\\beta_j^{(t+1)}\n",
    "=\n",
    "\\beta_j^{(t)}\n",
    "-\n",
    "\\eta \\cdot \\frac{1}{n}\n",
    "\\sum_{i=1}^{n}\n",
    "\\left( \\hat{y}_i - y_i \\right) x_i^j,\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\sum_{k=0}^{m} \\beta_k x_i^k.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Connection to the Normal Equation\n",
    "\n",
    "Setting the gradient to zero recovers the normal equation\n",
    "\n",
    "$$\n",
    "(X^\\top X)\\boldsymbol{\\beta} = X^\\top \\mathbf{y},\n",
    "$$\n",
    "\n",
    "which gradient descent solves iteratively without explicitly computing $(X^\\top X)^{-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4db00645",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54a81078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.09762701],\n",
       "        [1.43037873],\n",
       "        [1.20552675],\n",
       "        [1.08976637],\n",
       "        [0.8473096 ],\n",
       "        [1.29178823],\n",
       "        [0.87517442],\n",
       "        [1.783546  ],\n",
       "        [1.92732552],\n",
       "        [0.76688304],\n",
       "        [1.58345008],\n",
       "        [1.05778984],\n",
       "        [1.13608912],\n",
       "        [1.85119328],\n",
       "        [0.14207212],\n",
       "        [0.1742586 ],\n",
       "        [0.04043679],\n",
       "        [1.66523969],\n",
       "        [1.5563135 ],\n",
       "        [1.7400243 ],\n",
       "        [1.95723668],\n",
       "        [1.59831713],\n",
       "        [0.92295872],\n",
       "        [1.56105835],\n",
       "        [0.23654885],\n",
       "        [1.27984204],\n",
       "        [0.28670657],\n",
       "        [1.88933783],\n",
       "        [1.04369664],\n",
       "        [0.82932388],\n",
       "        [0.52911122],\n",
       "        [1.54846738],\n",
       "        [0.91230066],\n",
       "        [1.1368679 ],\n",
       "        [0.0375796 ],\n",
       "        [1.23527099],\n",
       "        [1.22419145],\n",
       "        [1.23386799],\n",
       "        [1.88749616],\n",
       "        [1.3636406 ],\n",
       "        [0.7190158 ],\n",
       "        [0.87406391],\n",
       "        [1.39526239],\n",
       "        [0.12045094],\n",
       "        [1.33353343],\n",
       "        [1.34127574],\n",
       "        [0.42076512],\n",
       "        [0.2578526 ],\n",
       "        [0.6308567 ],\n",
       "        [0.72742154],\n",
       "        [1.14039354],\n",
       "        [0.87720303],\n",
       "        [1.97674768],\n",
       "        [0.20408962],\n",
       "        [0.41775351],\n",
       "        [0.32261904],\n",
       "        [1.30621665],\n",
       "        [0.50658321],\n",
       "        [0.93262155],\n",
       "        [0.48885118],\n",
       "        [0.31793917],\n",
       "        [0.22075028],\n",
       "        [1.31265918],\n",
       "        [0.2763659 ],\n",
       "        [0.39316472],\n",
       "        [0.73745034],\n",
       "        [1.64198646],\n",
       "        [0.19420255],\n",
       "        [1.67588981],\n",
       "        [0.19219682],\n",
       "        [1.95291893],\n",
       "        [0.9373024 ],\n",
       "        [1.95352218],\n",
       "        [1.20969104],\n",
       "        [1.47852716],\n",
       "        [0.07837558],\n",
       "        [0.56561393],\n",
       "        [0.24039312],\n",
       "        [0.5922804 ],\n",
       "        [0.23745544],\n",
       "        [0.63596636],\n",
       "        [0.82852599],\n",
       "        [0.12829499],\n",
       "        [1.38494424],\n",
       "        [1.13320291],\n",
       "        [0.53077898],\n",
       "        [1.04649611],\n",
       "        [0.18788102],\n",
       "        [1.15189299],\n",
       "        [1.8585924 ],\n",
       "        [0.6371379 ],\n",
       "        [1.33482076],\n",
       "        [0.26359572],\n",
       "        [1.43265441],\n",
       "        [0.57881219],\n",
       "        [0.36638272],\n",
       "        [1.17302587],\n",
       "        [0.04021509],\n",
       "        [1.65788006],\n",
       "        [0.00939095]]),\n",
       " array([ 6.12773118,  9.19196269,  8.0822427 ,  5.73305541,  8.03018099,\n",
       "         9.77125385,  7.80430284,  9.17071317,  8.71122394,  7.35510084,\n",
       "         8.34717328,  8.39581459,  7.61654234, 10.53021887,  4.78258275,\n",
       "         5.22934897,  4.13181041, 10.78158957,  8.7958526 ,  9.62206225,\n",
       "        11.75486075,  7.44719232,  5.49839118,  9.65257177,  3.53652315,\n",
       "         9.78314731,  4.44650074,  8.92055869,  9.05403196,  7.96848643,\n",
       "         7.45489263,  9.55144679,  5.87567631,  9.32066865,  3.84473543,\n",
       "         8.50826938,  8.6198263 ,  7.54659389, 10.27656784,  9.01312847,\n",
       "         6.53347293,  5.52279093,  8.48402535,  5.68773873,  7.30603243,\n",
       "         7.87419268,  4.82714181,  6.62282151,  6.56486486,  6.58972646,\n",
       "         6.65126455,  7.17085827,  9.25591037,  4.64409942,  4.61741446,\n",
       "         5.6442904 ,  8.49524077,  5.31145086,  7.19387135,  4.37349204,\n",
       "         3.46255991,  5.10164255,  8.10465103,  5.46412914,  7.56263894,\n",
       "         7.15683051,  8.01313715,  5.69962394,  7.71176203,  4.11500584,\n",
       "         9.79051518,  8.52524993,  9.11581171,  6.80263458,  8.33712895,\n",
       "         3.57164847,  6.8234777 ,  3.64124786,  4.62937253,  4.27454627,\n",
       "         5.40986663,  8.41511002,  5.33430579,  8.24238396,  6.17417321,\n",
       "         6.43669992,  6.13927297,  3.01887197,  8.64370877,  9.8927198 ,\n",
       "         6.83227254,  8.32318993,  5.64761779,  7.64693763,  4.70219372,\n",
       "         5.78074269,  6.71566794,  3.4310955 ,  8.51810767,  4.04565202]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "n_samples = 100\n",
    "X = 2 * np.random.rand(n_samples, 1)          # shape (n, 1)\n",
    "true_w = 3.0\n",
    "true_b = 4.0\n",
    "noise = np.random.randn(n_samples)\n",
    "\n",
    "y = true_b + true_w * X[:, 0] + noise          # y = 4 + 3x + noise\n",
    "(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29894b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope (w): 2.99025910100489\n",
      "Intercept (b): 4.206340188711437\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "X_input = np.linspace(0,2,100).reshape(-1,1)\n",
    "y_input = model.predict(X_input)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X,y, color = \"green\", alpha = 0.4)\n",
    "plt.plot(X_input, y_input, color = \"blue\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Simple Linear Regression\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Slope (w):\", model.coef_[0])\n",
    "print(\"Intercept (b):\", model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c458a7",
   "metadata": {},
   "source": [
    "# 1.2 Ridge Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f3d62",
   "metadata": {},
   "source": [
    "## Ridge Linear Regression (L2-Regularized Linear Regression)\n",
    "\n",
    "We start from the standard linear regression model:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "w_1 \\\\\n",
    "w_2 \\\\\n",
    "\\vdots \\\\\n",
    "w_n\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "x_1^{(1)} & x_2^{(1)} & \\cdots & x_n^{(1)} \\\\\n",
    "x_1^{(2)} & x_2^{(2)} & \\cdots & x_n^{(2)} \\\\\n",
    "x_1^{(3)} & x_2^{(3)} & \\cdots & x_n^{(3)} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_1^{(m)} & x_2^{(m)} & \\cdots & x_n^{(m)}\n",
    "\\end{bmatrix}\n",
    "+ b\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "y^{(1)} & y^{(2)} & \\dots & y^{(m)}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This can be written compactly as:\n",
    "\n",
    "$$\n",
    "X\\mathbf{w} + b = \\mathbf{y}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Loss Function (with Ridge Regularization)\n",
    "\n",
    "In Ridge regression, we **penalize large weights** by adding an L2 regularization term.\n",
    "\n",
    "The Mean Squared Error loss becomes:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{w})\n",
    "=\n",
    "\\frac{1}{2m} \\| X\\mathbf{w} - \\mathbf{y} \\|_2^2\n",
    "+\n",
    "\\frac{\\lambda}{2m} \\| \\mathbf{w} \\|_2^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\lambda \\ge 0$ is the **regularization strength** -> changable not fixed nor depended on anything\n",
    "- the bias $b$ is **not regularized**\n",
    "- m = number of training samples\n",
    "\n",
    "---\n",
    "\n",
    "## Gradient of the Ridge Loss\n",
    "\n",
    "Taking the gradient with respect to $\\mathbf{w}$:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\mathbf{w}} \\mathcal{L}\n",
    "=\n",
    "\\frac{1}{m} X^\\top (X\\mathbf{w} - \\mathbf{y})\n",
    "+\n",
    "\\frac{\\lambda}{m} \\mathbf{w}\n",
    "$$\n",
    "\n",
    "Compare this with linear regression:\n",
    "\n",
    "- Linear: $\\frac{1}{m} X^\\top (X\\mathbf{w} - \\mathbf{y})$\n",
    "- Ridge: **adds** $\\frac{\\lambda}{m}\\mathbf{w}$\n",
    "\n",
    "---\n",
    "\n",
    "## Update Equation for Weights (Ridge Gradient Descent)\n",
    "\n",
    "> ### Ridge Gradient Descent Update\n",
    "> $$\n",
    "> \\boxed{\n",
    "> \\mathbf{w}^{(t+1)}\n",
    "> =\n",
    "> \\mathbf{w}^{(t)}\n",
    "> -\n",
    "> \\eta\n",
    "> \\left[\n",
    "> \\frac{1}{m} X^\\top\n",
    "> \\left( X\\mathbf{w}^{(t)} - \\mathbf{y} \\right)\n",
    "> +\n",
    "> \\frac{\\lambda}{m} \\mathbf{w}^{(t)}\n",
    "> \\right]\n",
    "> }\n",
    "> $$\n",
    "\n",
    "### Bias Update (unchanged)\n",
    "\n",
    "Since the bias is not regularized:\n",
    "\n",
    "$$\n",
    "b^{(t+1)}\n",
    "=\n",
    "b^{(t)}\n",
    "-\n",
    "\\eta \\cdot \\frac{1}{m}\n",
    "\\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Coordinate-wise Update (Ridge)\n",
    "\n",
    "For each weight $w_j$:\n",
    "\n",
    "$$\n",
    "w_j^{(t+1)}\n",
    "=\n",
    "w_j^{(t)}\n",
    "-\n",
    "\\eta\n",
    "\\left[\n",
    "\\frac{1}{m}\n",
    "\\sum_{i=1}^{m}\n",
    "(\\hat{y}_i - y_i)x_j^{(i)}\n",
    "+\n",
    "\\frac{\\lambda}{m} w_j^{(t)}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\sum_{k=1}^{n} w_k x_k^{(i)} + b\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Normal Equation (Ridge Regression)\n",
    "\n",
    "Setting the gradient to zero yields the **Ridge normal equation**:\n",
    "\n",
    "$$\n",
    "(X^\\top X + \\lambda I)\\mathbf{w} = X^\\top \\mathbf{y}\n",
    "$$\n",
    "\n",
    "Solving for $\\mathbf{w}$:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\mathbf{w}\n",
    "=\n",
    "(X^\\top X + \\lambda I)^{-1} X^\\top \\mathbf{y}\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## One-Sentence Summary\n",
    "\n",
    "> **Ridge regression modifies linear regression by adding an L2 penalty on the weights, leading to the update rule $\\mathbf{w}^{(t+1)} = \\mathbf{w}^{(t)} - \\eta \\left[\\frac{1}{m}X^\\top(X\\mathbf{w}-\\mathbf{y}) + \\frac{\\lambda}{m}\\mathbf{w}\\right]$ and the closed-form solution $(X^\\top X + \\lambda I)^{-1}X^\\top y$.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf01f174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2877498316739368\n",
      "Learned coefficients: [ 3.03599865e+00  1.01535907e-03 -9.47700963e-04  1.95533018e+00\n",
      " -2.15129692e-02]\n",
      "Intercept: -0.4461017788186246\n"
     ]
    }
   ],
   "source": [
    "linear_reg_lasso_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ridge\", Ridge(alpha = 1.0))\n",
    "])\n",
    "\n",
    "# Example data\n",
    "X = np.random.randn(200, 5)\n",
    "true_w = np.array([3, 0, 0, 2, 0]) # -> 3x_1 + 0x_2 + 0x_3 + 2x_4 + 0x_5 = y\n",
    "y = X @ true_w + np.random.randn(200) * 0.5\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "linear_reg_lasso_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linear_reg_lasso_pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "ridge_model = linear_reg_lasso_pipeline.named_steps[\"ridge\"]\n",
    "\n",
    "print(\"Learned coefficients:\", ridge_model.coef_)\n",
    "print(\"Intercept:\", ridge_model.intercept_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f2109f",
   "metadata": {},
   "source": [
    "## Cross-Validation Loss (k-Fold)\n",
    "\n",
    "Let the dataset be\n",
    "\n",
    "$$\n",
    "\\mathcal{D} = \\{(x_i, y_i)\\}_{i=1}^{m}\n",
    "$$\n",
    "\n",
    "Split the dataset into $k$ disjoint folds:\n",
    "\n",
    "$$\n",
    "\\mathcal{D}_1, \\mathcal{D}_2, \\dots, \\mathcal{D}_k\n",
    "$$\n",
    "\n",
    "such that\n",
    "\n",
    "$$\n",
    "\\mathcal{D}_j \\cap \\mathcal{D}_\\ell = \\varnothing \\quad (j \\neq \\ell),\n",
    "\\qquad\n",
    "\\bigcup_{j=1}^{k} \\mathcal{D}_j = \\mathcal{D}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Training and Validation Sets\n",
    "\n",
    "For fold $j$:\n",
    "\n",
    "**Training set**\n",
    "$$\n",
    "\\mathcal{D}_{\\text{train}}^{(j)} = \\mathcal{D} \\setminus \\mathcal{D}_j\n",
    "$$\n",
    "\n",
    "**Validation set**\n",
    "$$\n",
    "\\mathcal{D}_{\\text{val}}^{(j)} = \\mathcal{D}_j\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Ridge Regression Training (per fold)\n",
    "\n",
    "For a fixed regularization parameter $\\lambda$, train Ridge regression on the training set:\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\beta}}^{(j)}(\\lambda)\n",
    "=\n",
    "\\arg\\min_{\\boldsymbol{\\beta}}\n",
    "\\left[\n",
    "\\frac{1}{2|\\mathcal{D}_{\\text{train}}^{(j)}|}\n",
    "\\left\\| X_{\\text{train}}^{(j)}\\boldsymbol{\\beta}\n",
    "-\n",
    "\\mathbf{y}_{\\text{train}}^{(j)} \\right\\|_2^2\n",
    "+\n",
    "\\frac{\\lambda}{2|\\mathcal{D}_{\\text{train}}^{(j)}|}\n",
    "\\|\\boldsymbol{\\beta}\\|_2^2\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Validation Loss (per fold)\n",
    "\n",
    "Evaluate the trained model on the validation set:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{val}}^{(j)}(\\lambda)\n",
    "=\n",
    "\\frac{1}{|\\mathcal{D}_{\\text{val}}^{(j)}|}\n",
    "\\sum_{(x_i,y_i)\\in \\mathcal{D}_{\\text{val}}^{(j)}}\n",
    "\\left(\n",
    "y_i - x_i^\\top \\hat{\\boldsymbol{\\beta}}^{(j)}(\\lambda)\n",
    "\\right)^2\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Cross-Validation Loss\n",
    "\n",
    "The k-fold cross-validation loss is the average validation loss:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{CV}}(\\lambda)\n",
    "=\n",
    "\\frac{1}{k}\n",
    "\\sum_{j=1}^{k}\n",
    "\\mathcal{L}_{\\text{val}}^{(j)}(\\lambda)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Hyperparameter Selection\n",
    "\n",
    "Choose the regularization parameter that minimizes the CV loss:\n",
    "\n",
    "$$\n",
    "\\lambda^*\n",
    "=\n",
    "\\arg\\min_{\\lambda}\n",
    "\\mathcal{L}_{\\text{CV}}(\\lambda)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Final Model (after CV)\n",
    "\n",
    "Retrain Ridge regression on the full dataset using $\\lambda^*$:\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\beta}}_{\\text{final}}\n",
    "=\n",
    "\\arg\\min_{\\boldsymbol{\\beta}}\n",
    "\\left[\n",
    "\\frac{1}{2m}\\|X\\boldsymbol{\\beta}-\\mathbf{y}\\|_2^2\n",
    "+\n",
    "\\frac{\\lambda^*}{2m}\\|\\boldsymbol{\\beta}\\|_2^2\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "## Aggregated Cross-Validation Objective (Single Equation)\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\lambda^*\n",
    "=\n",
    "\\arg\\min_{\\lambda}\n",
    "\\;\n",
    "\\frac{1}{k}\n",
    "\\sum_{j=1}^{k}\n",
    "\\;\n",
    "\\frac{1}{|\\mathcal{D}_j|}\n",
    "\\sum_{(x_i,y_i)\\in\\mathcal{D}_j}\n",
    "\\left(\n",
    "y_i\n",
    "-\n",
    "x_i^\\top\n",
    "\\underset{\\boldsymbol{\\beta}}{\\arg\\min}\n",
    "\\left[\n",
    "\\frac{1}{2|\\mathcal{D}\\setminus\\mathcal{D}_j|}\n",
    "\\left\\|X_{-j}\\boldsymbol{\\beta}-\\mathbf{y}_{-j}\\right\\|_2^2\n",
    "+\n",
    "\\frac{\\lambda}{2|\\mathcal{D}\\setminus\\mathcal{D}_j|}\n",
    "\\|\\boldsymbol{\\beta}\\|_2^2\n",
    "\\right]\n",
    "\\right)^2\n",
    "}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9adc56cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.5689866029018293\n",
      "Coefficients: [ 3.04374265e+00  7.44225629e-04 -7.02342118e-04  1.95978350e+00\n",
      " -2.20605429e-02]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "ridge_cv_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ridge_cv\", RidgeCV(\n",
    "        alphas=np.logspace(-4, 4, 50),\n",
    "        cv=5\n",
    "    ))\n",
    "])\n",
    "\n",
    "ridge_cv_pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best alpha:\", ridge_cv_pipeline.named_steps[\"ridge_cv\"].alpha_)\n",
    "print(\"Coefficients:\", ridge_cv_pipeline.named_steps[\"ridge_cv\"].coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3810fcf",
   "metadata": {},
   "source": [
    "# 1.3 Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f478ab17",
   "metadata": {},
   "source": [
    "## LASSO Linear Regression (L1-Regularized Linear Regression)\n",
    "\n",
    "We start from the standard linear regression model:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "w_1 \\\\\n",
    "w_2 \\\\\n",
    "\\vdots \\\\\n",
    "w_n\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "x_1^{(1)} & x_2^{(1)} & \\cdots & x_n^{(1)} \\\\\n",
    "x_1^{(2)} & x_2^{(2)} & \\cdots & x_n^{(2)} \\\\\n",
    "x_1^{(3)} & x_2^{(3)} & \\cdots & x_n^{(3)} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_1^{(m)} & x_2^{(m)} & \\cdots & x_n^{(m)}\n",
    "\\end{bmatrix}\n",
    "+ b\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "y^{(1)} & y^{(2)} & \\dots & y^{(m)}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This can be written compactly as:\n",
    "\n",
    "$$\n",
    "X\\mathbf{w} + b = \\mathbf{y}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Loss Function (with LASSO Regularization)\n",
    "\n",
    "In LASSO regression, we **penalize large weights using the L1 norm**, encouraging sparsity.\n",
    "\n",
    "The Mean Squared Error loss becomes:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{w})\n",
    "=\n",
    "\\frac{1}{2m} \\| X\\mathbf{w} - \\mathbf{y} \\|_2^2\n",
    "+\n",
    "\\frac{\\lambda}{m} \\| \\mathbf{w} \\|_1\n",
    "$$\n",
    "\n",
    "-> L1 so not squared\n",
    "where:\n",
    "- $\\lambda \\ge 0$ is the **regularization strength** (tunable hyperparameter)\n",
    "- $\\|\\mathbf{w}\\|_1 = \\sum_{j=1}^{n} |w_j|$\n",
    "- the bias $b$ is **not regularized**\n",
    "- $m$ is the number of training samples\n",
    "\n",
    "---\n",
    "\n",
    "## Subgradient of the LASSO Loss\n",
    "\n",
    "The L1 norm is **not differentiable**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e8850ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.24108425701166153\n",
      "Learned coefficients: [ 3.02686856 -0.          0.          2.05373557  0.        ]\n",
      "Intercept: 0.06330908851996196\n"
     ]
    }
   ],
   "source": [
    "lasso_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),   # very important for Lasso\n",
    "    (\"lasso\", Lasso(alpha=0.1, max_iter=10000))\n",
    "])\n",
    "\n",
    "# Example data\n",
    "X = np.random.randn(200, 5)\n",
    "true_w = np.array([3, 0, 0, 2, 0])   # sparse true weights\n",
    "y = X @ true_w + np.random.randn(200) * 0.5\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "lasso_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = lasso_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE:\", mse)\n",
    "lasso_model = lasso_pipeline.named_steps[\"lasso\"]\n",
    "print(\"Learned coefficients:\", lasso_model.coef_)\n",
    "print(\"Intercept:\", lasso_model.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635edd73",
   "metadata": {},
   "source": [
    "## Cross-Validation Loss (k-Fold) â€” LASSO\n",
    "\n",
    "Let the dataset be\n",
    "\n",
    "$$\n",
    "\\mathcal{D} = \\{(x_i, y_i)\\}_{i=1}^{m}\n",
    "$$\n",
    "\n",
    "Split the dataset into $k$ disjoint folds:\n",
    "\n",
    "$$\n",
    "\\mathcal{D}_1, \\mathcal{D}_2, \\dots, \\mathcal{D}_k\n",
    "$$\n",
    "\n",
    "such that\n",
    "\n",
    "$$\n",
    "\\mathcal{D}_j \\cap \\mathcal{D}_\\ell = \\varnothing \\quad (j \\neq \\ell),\n",
    "\\qquad\n",
    "\\bigcup_{j=1}^{k} \\mathcal{D}_j = \\mathcal{D}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Training and Validation Sets\n",
    "\n",
    "For fold $j$:\n",
    "\n",
    "**Training set**\n",
    "$$\n",
    "\\mathcal{D}_{\\text{train}}^{(j)} = \\mathcal{D} \\setminus \\mathcal{D}_j\n",
    "$$\n",
    "\n",
    "**Validation set**\n",
    "$$\n",
    "\\mathcal{D}_{\\text{val}}^{(j)} = \\mathcal{D}_j\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## LASSO Regression Training (per fold)\n",
    "\n",
    "For a fixed regularization parameter $\\lambda$, train LASSO regression on the training set:\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\beta}}^{(j)}(\\lambda)\n",
    "=\n",
    "\\arg\\min_{\\boldsymbol{\\beta}}\n",
    "\\left[\n",
    "\\frac{1}{2|\\mathcal{D}_{\\text{train}}^{(j)}|}\n",
    "\\left\\| X_{\\text{train}}^{(j)}\\boldsymbol{\\beta}\n",
    "-\n",
    "\\mathbf{y}_{\\text{train}}^{(j)} \\right\\|_2^2\n",
    "+\n",
    "\\frac{\\lambda}{|\\mathcal{D}_{\\text{train}}^{(j)}|}\n",
    "\\|\\boldsymbol{\\beta}\\|_1\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\|\\boldsymbol{\\beta}\\|_1 = \\sum_{r=1}^{n} |\\beta_r|.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Validation Loss (per fold)\n",
    "\n",
    "Evaluate the trained model on the validation set:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{val}}^{(j)}(\\lambda)\n",
    "=\n",
    "\\frac{1}{|\\mathcal{D}_{\\text{val}}^{(j)}|}\n",
    "\\sum_{(x_i,y_i)\\in \\mathcal{D}_{\\text{val}}^{(j)}}\n",
    "\\left(\n",
    "y_i - x_i^\\top \\hat{\\boldsymbol{\\beta}}^{(j)}(\\lambda)\n",
    "\\right)^2\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Cross-Validation Loss\n",
    "\n",
    "The k-fold cross-validation loss is the average validation loss:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{CV}}(\\lambda)\n",
    "=\n",
    "\\frac{1}{k}\n",
    "\\sum_{j=1}^{k}\n",
    "\\mathcal{L}_{\\text{val}}^{(j)}(\\lambda)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Hyperparameter Selection\n",
    "\n",
    "Choose the regularization parameter that minimizes the CV loss:\n",
    "\n",
    "$$\n",
    "\\lambda^*\n",
    "=\n",
    "\\arg\\min_{\\lambda}\n",
    "\\mathcal{L}_{\\text{CV}}(\\lambda)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Final Model (after CV)\n",
    "\n",
    "Retrain LASSO regression on the full dataset using $\\lambda^*$:\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\beta}}_{\\text{final}}\n",
    "=\n",
    "\\arg\\min_{\\boldsymbol{\\beta}}\n",
    "\\left[\n",
    "\\frac{1}{2m}\\|X\\boldsymbol{\\beta}-\\mathbf{y}\\|_2^2\n",
    "+\n",
    "\\frac{\\lambda^*}{m}\\|\\boldsymbol{\\beta}\\|_1\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Aggregated Cross-Validation Objective (Single Equation)\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\lambda^*\n",
    "=\n",
    "\\arg\\min_{\\lambda}\n",
    "\\;\n",
    "\\frac{1}{k}\n",
    "\\sum_{j=1}^{k}\n",
    "\\;\n",
    "\\frac{1}{|\\mathcal{D}_j|}\n",
    "\\sum_{(x_i,y_i)\\in\\mathcal{D}_j}\n",
    "\\left(\n",
    "y_i\n",
    "-\n",
    "x_i^\\top\n",
    "\\underset{\\boldsymbol{\\beta}}{\\arg\\min}\n",
    "\\left[\n",
    "\\frac{1}{2|\\mathcal{D}\\setminus\\mathcal{D}_j|}\n",
    "\\left\\|X_{-j}\\boldsymbol{\\beta}-\\mathbf{y}_{-j}\\right\\|_2^2\n",
    "+\n",
    "\\frac{\\lambda}{|\\mathcal{D}\\setminus\\mathcal{D}_j|}\n",
    "\\|\\boldsymbol{\\beta}\\|_1\n",
    "\\right]\n",
    "\\right)^2\n",
    "}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ad900b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.01757510624854793\n",
      "Coefficients: [ 3.1090834  -0.          0.02987722  2.1387873   0.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lasso_cv_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lasso_cv\", LassoCV(\n",
    "        alphas=np.logspace(-4, 1, 50),\n",
    "        cv=5,\n",
    "        max_iter=10000\n",
    "    ))\n",
    "])\n",
    "\n",
    "lasso_cv_pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best alpha:\", lasso_cv_pipeline.named_steps[\"lasso_cv\"].alpha_)\n",
    "print(\"Coefficients:\", lasso_cv_pipeline.named_steps[\"lasso_cv\"].coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a4af95",
   "metadata": {},
   "source": [
    "## Linear vs Ridge vs LASSO Regression (Side-by-Side)\n",
    "\n",
    "### Linear Regression (No Regularization)\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\hat{\\boldsymbol{\\beta}}_{\\text{Linear}}\n",
    "=\n",
    "\\arg\\min_{\\boldsymbol{\\beta}}\n",
    "\\;\n",
    "\\frac{1}{2m}\n",
    "\\left\\|\n",
    "X\\boldsymbol{\\beta} - \\mathbf{y}\n",
    "\\right\\|_2^2\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Ridge Regression (L2 Regularization)\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\hat{\\boldsymbol{\\beta}}_{\\text{Ridge}}\n",
    "=\n",
    "\\arg\\min_{\\boldsymbol{\\beta}}\n",
    "\\;\n",
    "\\frac{1}{2m}\n",
    "\\left\\|\n",
    "X\\boldsymbol{\\beta} - \\mathbf{y}\n",
    "\\right\\|_2^2\n",
    "+\n",
    "\\frac{\\lambda}{2m}\n",
    "\\left\\|\n",
    "\\boldsymbol{\\beta}\n",
    "\\right\\|_2^2\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### LASSO Regression (L1 Regularization)\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\hat{\\boldsymbol{\\beta}}_{\\text{LASSO}}\n",
    "=\n",
    "\\arg\\min_{\\boldsymbol{\\beta}}\n",
    "\\;\n",
    "\\frac{1}{2m}\n",
    "\\left\\|\n",
    "X\\boldsymbol{\\beta} - \\mathbf{y}\n",
    "\\right\\|_2^2\n",
    "+\n",
    "\\frac{\\lambda}{m}\n",
    "\\left\\|\n",
    "\\boldsymbol{\\beta}\n",
    "\\right\\|_1\n",
    "}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb228fb3",
   "metadata": {},
   "source": [
    "## Linear vs Ridge vs LASSO (Unified Objective Form)\n",
    "\n",
    "All three models minimize the same empirical risk with different regularization terms:\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\beta}}\n",
    "=\n",
    "\\arg\\min_{\\boldsymbol{\\beta}}\n",
    "\\left\\{\n",
    "\\frac{1}{2m}\n",
    "\\left\\|\n",
    "X\\boldsymbol{\\beta} - \\mathbf{y}\n",
    "\\right\\|_2^2\n",
    "+\n",
    "\\mathcal{R}(\\boldsymbol{\\beta})\n",
    "\\right\\},\n",
    "$$\n",
    "\n",
    "where the regularization term $\\mathcal{R}(\\boldsymbol{\\beta})$ is defined as\n",
    "\n",
    "$$\n",
    "\\mathcal{R}(\\boldsymbol{\\beta})\n",
    "=\n",
    "\\begin{cases}\n",
    "0,\n",
    "& \\text{Linear Regression} \\\\[6pt]\n",
    "\n",
    "\\displaystyle\n",
    "\\frac{\\lambda}{2m}\n",
    "\\left\\|\n",
    "\\boldsymbol{\\beta}\n",
    "\\right\\|_2^2,\n",
    "& \\text{Ridge Regression (L2)} \\\\[10pt]\n",
    "\n",
    "\\displaystyle\n",
    "\\frac{\\lambda}{m}\n",
    "\\left\\|\n",
    "\\boldsymbol{\\beta}\n",
    "\\right\\|_1,\n",
    "& \\text{LASSO Regression (L1)}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Aggregated Cross-Validation Objective (All Models)\n",
    "\n",
    "The optimal regularization parameter $\\lambda^*$ is chosen by minimizing the k-fold cross-validation loss:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\lambda^*\n",
    "=\n",
    "\\arg\\min_{\\lambda}\n",
    "\\;\n",
    "\\frac{1}{k}\n",
    "\\sum_{j=1}^{k}\n",
    "\\;\n",
    "\\frac{1}{|\\mathcal{D}_j|}\n",
    "\\sum_{(x_i,y_i)\\in\\mathcal{D}_j}\n",
    "\\left(\n",
    "y_i\n",
    "-\n",
    "x_i^\\top\n",
    "\\hat{\\boldsymbol{\\beta}}^{(-j)}(\\lambda)\n",
    "\\right)^2\n",
    "}\n",
    "$$\n",
    "\n",
    "where the model parameters trained **excluding fold $j$** are given by\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\beta}}^{(-j)}(\\lambda)\n",
    "=\n",
    "\\arg\\min_{\\boldsymbol{\\beta}}\n",
    "\\left\\{\n",
    "\\frac{1}{2|\\mathcal{D}\\setminus\\mathcal{D}_j|}\n",
    "\\left\\|\n",
    "X_{-j}\\boldsymbol{\\beta}-\\mathbf{y}_{-j}\n",
    "\\right\\|_2^2\n",
    "+\n",
    "\\mathcal{R}_\\lambda(\\boldsymbol{\\beta})\n",
    "\\right\\}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\mathcal{R}_\\lambda(\\boldsymbol{\\beta})\n",
    "=\n",
    "\\begin{cases}\n",
    "0,\n",
    "& \\text{Linear Regression} \\\\[6pt]\n",
    "\n",
    "\\displaystyle\n",
    "\\frac{\\lambda}{2|\\mathcal{D}\\setminus\\mathcal{D}_j|}\n",
    "\\left\\|\n",
    "\\boldsymbol{\\beta}\n",
    "\\right\\|_2^2,\n",
    "& \\text{Ridge Regression} \\\\[10pt]\n",
    "\n",
    "\\displaystyle\n",
    "\\frac{\\lambda}{|\\mathcal{D}\\setminus\\mathcal{D}_j|}\n",
    "\\left\\|\n",
    "\\boldsymbol{\\beta}\n",
    "\\right\\|_1,\n",
    "& \\text{LASSO Regression}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "- **Linear Regression**  \n",
    "  No regularization â†’ lowest bias, highest variance\n",
    "\n",
    "- **Ridge Regression**  \n",
    "  L2 penalty â†’ coefficient shrinkage, numerical stability\n",
    "\n",
    "- **LASSO Regression**  \n",
    "  L1 penalty â†’ sparsity and feature selection\n",
    "\n",
    "Cross-validation selects the $\\lambda$ that best balances **biasâ€“variance tradeoff**.\n",
    "\n",
    "---\n",
    "\n",
    "## One-Line Master Equation (Ultra-Compact)\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\hat{\\boldsymbol{\\beta}}^{*}\n",
    "=\n",
    "\\arg\\min_{\\boldsymbol{\\beta}}\n",
    "\\;\n",
    "\\mathbb{E}_{\\text{CV}}\n",
    "\\left[\n",
    "\\|X\\boldsymbol{\\beta}-\\mathbf{y}\\|_2^2\n",
    "+\n",
    "\\mathcal{R}_\\lambda(\\boldsymbol{\\beta})\n",
    "\\right]\n",
    "}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dcf4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
